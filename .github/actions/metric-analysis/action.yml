name: Metric Analysis
description: Analyze Prometheus metrics

inputs:
  baseline_count:
    description: 'Number of baseline runs to find'
    default: '3'
  monitoring_period:
    description: 'Monitoring period in seconds'
    default: '900'
  query:
    description: 'Prometheus query'
    required: true
  metric_name:
    description: 'Metric name for display'
    required: true
  x_axis_label:
    description: 'X-axis label'
    default: 'Time'
  y_axis_label:
    description: 'Y-axis label'
    default: ''
  workflow:
    description: 'Workflow filename'
    default: '.github/workflows/ci.yml'
  job_name:
    description: 'Job name to search for baselines. Uses current job if not specified.'
    default: ''
  prometheus_url:
    description: 'Prometheus server URL'
    default: 'https://prometheus-poc.avax-dev.network'
  prometheus_username:
    required: true
  prometheus_password:
    required: true
  step_size:
    description: 'Prometheus query step size'
    default: '15s'
  timezone:
    description: 'Display timezone'
    default: 'US/Eastern'
  github_token:
    description: 'GitHub token'
    default: ${{ github.token }}

runs:
  using: composite
  steps:
    - name: Build baseline configuration
      id: build-config
      uses: actions/github-script@v7
      with:
        github-token: ${{ inputs.github_token }}
        script: |
          const fs = require('fs');
          const path = require('path');

          const BASELINE_COUNT = parseInt('${{ inputs.baseline_count }}');
          const WORKFLOW = '${{ inputs.workflow }}';
          const CURRENT_RUN_ID = context.runId.toString();
          const ACTION_PATH = process.env.GITHUB_ACTION_PATH;

          // Get current run metadata
          const metadataFile = '/tmp/run-metadata/run_metadata.json';
          if (!fs.existsSync(metadataFile)) {
            throw new Error('Current run metadata not found');
          }

          const currentMetadata = JSON.parse(fs.readFileSync(metadataFile, 'utf8'));
          console.log(`Current run job: ${currentMetadata.job_id}`);

          // Get successful workflow runs
          const { data: workflowRuns } = await github.rest.actions.listWorkflowRuns({
            owner: context.repo.owner,
            repo: context.repo.repo,
            workflow_id: WORKFLOW,
            status: 'completed',
            conclusion: 'success',
            per_page: 50
          });

          const baselines = [];

          for (const run of workflowRuns.workflow_runs) {
            if (baselines.length >= BASELINE_COUNT) break;
            if (run.id.toString() === CURRENT_RUN_ID) continue;

            // Check for metadata artifact
            try {
              const { data: artifacts } = await github.rest.actions.listWorkflowRunArtifacts({
                owner: context.repo.owner,
                repo: context.repo.repo,
                run_id: run.id
              });

              const metadataArtifact = artifacts.artifacts.find(artifact =>
                artifact.name === `run-metadata-${currentMetadata.job_id}-${run.id}` && !artifact.expired
              );

              if (metadataArtifact) {
                baselines.push({
                  name: `Baseline ${run.run_number} (#${run.id})`,
                  start_time: new Date(run.created_at).getTime(),
                  end_time: new Date(run.updated_at).getTime(),
                  labels: {
                    gh_run_id: run.id.toString(),
                    gh_job_id: currentMetadata.job_id,
                    gh_run_attempt: "1",
                    gh_repo: context.repo.owner + "/" + context.repo.repo,
                    is_ephemeral_node: "false"
                  }
                });

                console.log(`Added baseline: Run ${run.run_number}`);
              }
            } catch (error) {
              console.log(`Error checking artifacts for run ${run.id}: ${error.message}`);
            }
          }

          console.log(`Found ${baselines.length} baselines with metadata artifacts`);

          // Create output file in action directory
          const outputFile = `metric_visualization_${CURRENT_RUN_ID}.html`;
          const outputPath = path.join(ACTION_PATH, outputFile);

          // Build configuration
          const config = {
            query: '${{ inputs.query }}',
            metric_name: '${{ inputs.metric_name }}',
            x_axis_label: '${{ inputs.x_axis_label }}',
            y_axis_label: '${{ inputs.y_axis_label }}' || '${{ inputs.metric_name }}',
            candidate: {
              start_time: currentMetadata.start_timestamp * 1000,
              end_time: currentMetadata.end_timestamp * 1000,
              name: `Candidate (#${CURRENT_RUN_ID})`,
              labels: {
                gh_run_id: CURRENT_RUN_ID,
                gh_job_id: currentMetadata.job_id,
                gh_run_attempt: currentMetadata.run_attempt,
                gh_repo: currentMetadata.repository,
                is_ephemeral_node: "false"
              }
            },
            baselines: baselines,
            output_file: outputPath
          };

          const configPath = path.join(ACTION_PATH, 'metric_config.json');
          fs.writeFileSync(configPath, JSON.stringify(config, null, 2));

          console.log(`Config written to: ${configPath}`);
          console.log(`Plot created at: ${outputPath}`);

          core.setOutput('config_path', configPath);
          core.setOutput('output_file', outputPath);
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    - name: Install Python dependencies
      shell: bash
      run: pip install -r $GITHUB_ACTION_PATH/requirements.txt
    - name: Run metric analysis
      shell: bash
      env:
        PROMETHEUS_ID: ${{ inputs.prometheus_username }}
        PROMETHEUS_PASSWORD: ${{ inputs.prometheus_password }}
      run: |
        python $GITHUB_ACTION_PATH/plot.py \
          --config ${{ steps.build-config.outputs.config_path }} \
          --prometheus-url "${{ inputs.prometheus_url }}" \
          --step-size "${{ inputs.step_size }}" \
          --timezone "${{ inputs.timezone }}"
    - name: Upload visualization artifact
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: metric-analysis-${{ github.job }}-${{ github.run_id }}
        path: |
          ${{ steps.build-config.outputs.output_file }}
          ${{ steps.build-config.outputs.config_path }}
        retention-days: 14
